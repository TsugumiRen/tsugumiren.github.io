---
title: 当我们谈论 CAP 时，我们在谈论什么
date: 2024-10-06 23:58:00 +0800
categories: [Computer System, Distributed System]
tags: [Distributed System, CAP]
description: 一点关于 CAP 的小小介绍
---

>每当你提到你熟悉一点分布式理论时，面试官总会跃跃欲试地问你，CAP 是什么？然而坊间对 CAP 的解释多有偏颇，有些时候甚至问出这个问题的面试官自己都不甚了了。这篇小文就尝试来写一写，到底什么是 CAP。

## CAP 是什么

CAP 是三个英文单词的缩写，即 Consistency (一致性)、Availability (可用性) 和 Partition Tolerance (可容忍网络分割)。CAP 理论则是关于分布式的数据存储系统遭遇网络分割时，在数据的一致性和可用性之间进行权衡的理论。一些文章中把 CAP 说成是 C、A、P 中三选二，然而值得注意的是，这样的说法却稍微有点令人误解。如果可以选择，那我为什么不选择 C 和 A，而让 Partition 永远不发生呢？网络故障归根结底，是没有办法选择的。所以更好的说法其实是：

>当一切正常时，系统可以保持一致性地向外提供服务；
>
>当网络分割 (即某个分布式系统因为网络故障成为了孤立的两部分，彼此之间不能够进行通信) 发生时，我们在下面两者中选择其一：
>
>1. 顾及数据的一致性，此时整个系统便不能够向外提供服务，否则数据的一致性就会被破坏；
>2. 继续保持服务的可用性，但在这时我们数据的一致性就被破坏了，需要在分布式系统网络分割解除后手动处理数据间的不一致。

关于网络分割时还保持向外提供服务为什么会破坏一致性，我们可以简单举个例子。假设 A 和 B 是两个将会被分割的区域，X 在这两个区域中都存有副本。

在正常情况下，我们对 X 的读写会一致地反映到两个数据副本中：

| A           | B           |
| ----------- | ----------- |
| Read X -> 0 |             |
| Write X 1   |             |
|             | Inc X       |
|             | Read X -> 2 |
| Read X -> 2 |             |

而如果发生了网络分割，并且我们执意要向外提供服务，那么相同的过程就会变成：

| A           | B           |
| ----------- | ----------- |
| Read X -> 0 |             |
| Write X 1   |             |
| Partition   | Partition   |
|             | Inc X       |
|             | Read X -> 2 |
| Read X -> 1 |             |

这里的两个数据副本的状态就处于不一致的状态了。

CAP 理论的正确性是经过数学证明的[^1]，这或许会让我们感到一丝沮丧——难道就没有其他办法了吗？当然有，让我们继续。

## 与 CAP 和解

### 放松一致性要求

CAP 理论中的 Consistency 其实是最强的线性一致性，即 Linearizability。在这种一致性中，所有数据操作需要具有全序关系，也就是说，任意两个操作 A 和 B，要么 A 先于 B 发生，要么 B 先于 A 发生。这样的一致性实际上就相当于尽管我们有多份数据存在不同的地方、被多个外部实体并发地读或写，但表现得却像我们只有一份数据、在一台机子上单线程地对这份数据读或写一样。

但有时候我们或许用不到这么强的一致性，即我们可以容忍对一些数据的读或写是同时发生的，而至于其产生的冲突 (Conflict) 则留待后续用某种算法或是人工进行解决。对于这些稍弱的一致性，比较常见的有两种：Causality 和 Eventually Consistency。

Eventually Consistency 是一种比较整蛊的一致性——最终一致性，即，最终数据会是一致的。它并没有指明这个“最终”所会发生的时机，所以其实就相当于什么就没保证。采用这种一致性，我们当然能对外界提供服务。

Causality 则描述的是一种偏序关系，它保留了数据操作中的“因果”，或者说 happens-before 关系 (稍微熟悉并发编程一点的读者可能对这个词很熟悉)。这样说或许有一点抽象，其基于这样一种推论来定义操作的顺序：如果我们看到了一个数据被写的值，那么这个数据被写的操作一定发生于我们即将要进行的操作之前；对于那些我们没有去注意的数据，对其的读写操作是和我们即将要进行的操作并发的。对于那些有 happens-before 关系的数据操作，更晚发生的数据操作是正确并应该被保留的；而对于存在并发关系的数据操作，何者代表数据的正确值则留待以某种算法来抉择。在实际中，一般会使用 Vector Clock 这样的算法来确保 Causality[^2]。如果我们采用这种一致性，当网络分割发生时，那些不并发的操作可以正常地被进行，而并发的操作则需要留待后面解决冲突。

### 使用共识算法

上面的方法是采用牺牲一些一致性的方法来提供可用性，这个方法则是尽量缓和网络分割发生的条件。

当我们使用 2-PC (2-Phase Commit) 来确保数据一致性时，系统中任何一个部分的故障都会造成网络分割，使得无论分割后的哪部分的服务都不再可用。但我们并不一定非要使用 2-PC 才行，实际上我们只需要保证系统中的大部分 (Majority)，即大于等于$\lfloor\frac{n}{2}\rfloor+1$的结点都认同某一个数据，我们便能保证这个数据最终能在整个系统中变得一致。这类算法被称为共识 (Consensus) 算法，我们耳熟能详的 Paxos、 ZAB、 Raft 便是典型的共识算法。

在使用共识算法的前提下，网络分割只会造成结点数量比较少的那部分不再可用，而那些节点数量大于等于$\lfloor\frac{n}{2}\rfloor+1$的部分仍能继续保持可用。

正如《Designing Data-Intensive Applications》一书所说，在如今，CAP 理论更常见于面试之中而不是理论研究与实际应用之中。不过知道 CAP 理论就像知道停机问题一样，能让我们感受到计算机的能与不能，更体会到 trade-off 在计算机这门学科中的无处不在。

[^1]: [Brewer's conjecture and the feasibility of consistent, available, partition-tolerant web services](https://dl.acm.org/doi/10.1145/564585.564601)
[^2]: [Why Logical Clocks are Easy](https://queue.acm.org/detail.cfm?id=2917756)
